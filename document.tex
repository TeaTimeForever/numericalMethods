\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsfonts}
\usepackage{natbib}
\usepackage{upquote}
\usepackage{datetime}
\usepackage{multicol}
\usepackage{listings}

\setlength{\voffset}{-3cm}
\setlength{\textheight}{700pt}

\title{Численные методы: Лабораторная работа №1}
\author{Группа 4001BV: Карина Пилюшонока \and Александр Степанов \and Борис
Кувшинников}
\date \today

\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage
\section{Формулировка задания}

\subsection{Метод исключения Гаусса с ведущим элементом}
Написать программную реализацию алгоритма для решения системы линейных
уравнений методом исключения Гаусса с ведущим элементом.
Для проверки алгоритма использовать следующие системы:

\begin{displaymath}
  \left\{ \begin{array}{ll}
  x_{1} - 2x_{2} + x_{3} = 2\\
  2x_{1} - 5x_{2} - x_{3} = -1\\
  -7x_{1} + x_{3} = -2\\
\end{array} \right.
\end{displaymath}
\rule[1mm]{10cm}{0.1mm}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  5x_{1} - 5x_{2} - 3x_{3} + 4x_{4} = -11\\
  x_{1} - 4x_{2} + 6x_{3} - 4x_{4} = -10\\
  -2x_{1} - 5x_{2} + 4x_{3} - 5x_{4} = -12\\
  -3x_{1} - 3x_{2} + 5x_{3} - 5x_{4} = 8\\
\end{array} \right.
\end{displaymath}
\rule[1mm]{10cm}{0.1mm}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  0.78x_{1} + 0.563x_{2} = 0.217\\
  0.913x_{1} + 0.659x_{2} = 0.254\\
\end{array} \right.
\end{displaymath}

\subsection{Метод прогонки}
Написать программную реализацию алгоритма для решения системы линейных
уравнений методом прогонки для трехдиагональных матриц.
Также, необходимо сравнить метод прогонки и метод исключения Гаусса с выбором
ведущего элемента.
Для проверки алгоритма в списке линейных уравнений указанных
в методическом пособии для данной лабораторной работы не оказалось трехдиагональных матриц,
поэтому мы самостоятельно подготовили тестовые варианты для данной
части задания.
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  x_{1} + 4x_{2} = 17\\
  3x_{1} + 2x_{2} + 7x_{3} = 35\\
  x_{2} + 3x_{3} = 9\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
\left\{ \begin{array}{ll}
  x_{1} = 5\\
  x_{2} = 3\\
  x_{3} = 2\\
\end{array} \right.
\end{displaymath}
\end{multicols}
\rule[1mm]{10cm}{0.1mm}
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  0.2x_{1} + 1.2x_{2} = 3.42\\
  5.6x_{1} - 0.7x_{2} + x_{3} = 10.62\\
  -0.5x_{2} + 1.1x_{3} + 0.07x_{4} = -0.636\\
  1.9x_{3} + 1.3x_{4} = 4.92\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
\left\{ \begin{array}{ll}
  x_{1} = 1.5\\
  x_{2} = 2.6\\
  x_{3} = 0.4\\
  x_{4} = 3.2\\
\end{array} \right.
\end{displaymath}
\end{multicols}

\subsection{Определение числа обусловленности матрицы}
Написать программную реализацию алгоритма, для вычисления значения числа
обусловленности для матриц. В промежуточных вычислениях используется Евклидовая
норма матрицы. Для проверки алгоритма использовать следующие системы:

\begin{displaymath}
  \left\{ \begin{array}{ll}
  2x_{1} - x_{2} - x_{3}= 5\\
  x_{1} + 3x_{2} - 2x_{3} = 7\\
  x_{1} + 2x_{2} + 3x_{3} = 10\\
\end{array} \right.
\end{displaymath}
\rule[1mm]{10cm}{0.1mm}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  0.78x_{1} + 0.563x_{2} = 0.217\\
  0.913x_{1} + 0.659x_{2} = 0.254\\
\end{array} \right.
\end{displaymath}
Пояснить полученные результаты вычислений.

\section{Ход выполнения заданий}
\subsection{Метод исключения Гаусса с ведущим элементом}
Полученные результаты:
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  x_{1} - 2x_{2} + x_{3} = 2\\
  2x_{1} - 5x_{2} - x_{3} = -1\\
  -7x_{1} + x_{3} = -2\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
\left\{ \begin{array}{ll}
  x_{1} = 0.52\\
  x_{2} = 0.08\\
  x_{3} = 1.64\\
\end{array} \right.
\end{displaymath}
\end{multicols}
\rule[1mm]{10cm}{0.1mm}
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  5x_{1} - 5x_{2} - 3x_{3} + 4x_{4} = -11\\
  x_{1} - 4x_{2} + 6x_{3} - 4x_{4} = -10\\
  -2x_{1} - 5x_{2} + 4x_{3} - 5x_{4} = -12\\
  -3x_{1} - 3x_{2} + 5x_{3} - 5x_{4} = 8\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
\left\{ \begin{array}{ll}
  x_{1} = -12.8235\\
  x_{2} = -2.2941\\
  x_{3} = 11.7647\\
  x_{4} = 19.2353\\
\end{array} \right.
\end{displaymath}
\end{multicols}
\rule[1mm]{10cm}{0.1mm}
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  0.78x_{1} + 0.563x_{2} = 0.217\\
  0.913x_{1} + 0.659x_{2} = 0.254\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
\left\{ \begin{array}{ll}
  x_{1} = 1\\
  x_{2} = -1\\
\end{array} \right.
\end{displaymath}
\end{multicols}
\subsection{Метод прогонки}
Полученные результаты:
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  x_{1} + 4x_{2} = 17\\
  3x_{1} + 2x_{2} + 7x_{3} = 35\\
  x_{2} + 3x_{3} = 9\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
\left\{ \begin{array}{ll}
  x_{1} = 5\\
  x_{2} = 3\\
  x_{3} = 2\\
\end{array} \right.
\end{displaymath}
\end{multicols}
\rule[1mm]{10cm}{0.1mm}
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  0.2x_{1} + 1.2x_{2} = 3.42\\
  5.6x_{1} - 0.7x_{2} + x_{3} = 10.62\\
  -0.5x_{2} + 1.1x_{3} + 0.07x_{4} = -0.636\\
  1.9x_{3} + 1.3x_{4} = 4.92\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
\left\{ \begin{array}{ll}
  x_{1} = 1.5\\
  x_{2} = 2.6\\
  x_{3} = 0.4\\
  x_{4} = 3.2\\
\end{array} \right.
\end{displaymath}
\end{multicols}

\subsection{Определение числа обусловленности матрицы}
Полученные результаты:
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  2x_{1} - x_{2} - x_{3}= 5\\
  x_{1} + 3x_{2} - 2x_{3} = 7\\
  x_{1} + 2x_{2} + 3x_{3} = 10\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
  cond = 3.4236
\end{displaymath}
\end{multicols}
\rule[1mm]{10cm}{0.1mm}
\begin{multicols}{2}
\begin{displaymath}
  \left\{ \begin{array}{ll}
  0.78x_{1} + 0.563x_{2} = 0.217\\
  0.913x_{1} + 0.659x_{2} = 0.254\\
\end{array} \right.
\end{displaymath}

\begin{displaymath}
  cond = 2.1932e+6
\end{displaymath}
\end{multicols}
Число обусловленности второй матрицы многократно превышает число первой
, поскольку она содержить в себе маленькие дробные числа.
Это означает, что при работе с матрицами подобного типа, стоит уделить
большое внимание алгоритмам, которые будут ими оперировать.

 \section{Сравнительный анализ методов прогонки и исключения Гаусса с
выборов ведущего элемента}
Поскольку метод прогонки решает уравнения только с трехдиагональной матрицей,
то и в качестве общей матрицы для сравнения была выбрана трехдиагональная
матрица из примера.
\begin{displaymath}
  \left\{ \begin{array}{ll}
  0.2x_{1} + 1.2x_{2} = 3.42\\
  5.6x_{1} - 0.7x_{2} + x_{3} = 10.62\\
  -0.5x_{2} + 1.1x_{3} + 0.07x_{4} = -0.636\\
  1.9x_{3} + 1.3x_{4} = 4.92\\
\end{array} \right.
\end{displaymath}
\begin{table}
\begin{tabular}{lll}
~                       & время  & результат \\
метод прогонки          & 0.1248 & [1.5 2.6 0.4 3.2]\\
метод исключения Гаусса & 0.2652 & [1.5 2.6 0.4 3.2]\\
\end{tabular}
\end{table}
Из результатов анализа видно, что даже на таблице такого маленького порядка
метод прогонки работает быстрее в 2 раза.
Однако, стоит заметить, что метод прогонки подогнан под специальный тип
уравнений и не уверсален в отличии от метода исключения Гаусса.
\section{Программная реализация}
\subsection{Метод исключения Гаусса с ведущим элементом}
\begin{lstlisting}
classdef main
    methods (Static)
        function index = max_abs_in_column(column, from)
            s = size(column);
            max = 0;
            max_index = -9999;

            for i = from : s(1)
                if max < abs(column(i))
                    max = abs(column(i));
                    max_index = i;
                end
            end
            index = max_index;
        end

        function A = swap_rows(Arr, from, to)
            A = Arr;
            A([from to],:) = A([to from],:);    
        end

        function res = zeroing_row(main_row, row, index)
            res = main_row * (-row(index)/main_row(index)) + row;
        end

        % "AXB" A - must be a diagonal matrix
        function X = reverse_gauss(AXB)
            AXB_dimentions = size(AXB);
            B = AXB(:, AXB_dimentions(2));
            A = AXB(:, 1:AXB_dimentions(2)-1);
            A_dimentions = size(A);

             for i=  A_dimentions(1): -1 : 1
                X(i) = B(i)/A(i,i);
                A(:, i) = A(:, i) * X(i);
                for k = 1 : A_dimentions(2)
                   B(k) = B(k) - A(k, i);
                end
            end
        end

        function res = gauss(A, B)
            dimentions = size(A);
            AXB = [A B];
            for j = 1 : dimentions(2)
                max = main.max_abs_in_column(AXB(:,j), j);
                AXB = main.swap_rows(AXB, j, max); 
                main_row = j;

                for i = main_row +1 : dimentions(1)
                    AXB(i, :) = main.zeroing_row(AXB(main_row, :), AXB(i, :), j);  %%%%
                end
            end
            res = main.reverse_gauss(AXB);
        end

        function res = testStart()
            %res = main.gauss([2 1 -1; -3 -1 2; -2 1 2], [8; -11; -3]); % 3 2 -1
            %res = main.gauss([2 -1 0; -1 -1 4; 1 2 3], [4; -1; 10]); % 3 2 1
            %res = main.gauss([1 -2 1; 2 -5 -1; -7 0 1], [2; -1; -2]);
            %res = main.gauss([5 -5 -3 4; 1 -4 6 -4; -2 -5 4 -5; -3 -3 5 -5], [-11; -10; -12; 8]); % 3 2 1 
            %res = main.gauss([0.78 0.563; 0.913 0.659], [0.217; 0.254])
        end
    end
end

\end{lstlisting}
\subsection{Метод прогонки}
\begin{lstlisting}
classdef tridiagonal_matrix 
    methods (Static)
        function res = solveTridiagonal(A, B)
           AuxM = tridiagonal_matrix.getAuxiliaryMatrix(A, B);
           disp(AuxM);
            s = size(AuxM);
            X(s(1)) = AuxM(s(1), 1);
            for i = s(1)-1 : -1: 1
               X(i) = AuxM(i, 1) - AuxM(i, 2) * X(i+1);
            end
            res = X;
        end
        
        function res = testStart()
            %A = [1 4 0; 
            %     3 2 7; 
            %     0 1 3];
            %B = [17; 35; 9];
            % 5 3 2
            
            A = [0.2 1.2 0 0;   
                 5.6 0.7 1 0;  
                 0  -0.5 1.1 0.07;  
                 0   0   1.9 1.3];
            B = [3.42; 10.62; -0.636; 4.92];
            %1.5 2.6 0.4 3.2
            
            %A = [1 4 0 0;    
            %     2 1 4 0;  
            %     0 2 1 1;  
            %     0 0 2 3];
            %B = [17; 21; 12; 16];
            %5 3 2 4
            res = tridiagonal_matrix.solveTridiagonal(A, B);
        end

        function res = getAuxiliaryMatrix(A, B)
            AuxBetaAlpha(1,1) = B(1) / A(1,1);
            AuxBetaAlpha(1,2) = A(1,2) / A(1,1);
            s = size(A);
            for i = 2 : s(1) - 1 
                AuxBetaAlpha(i,1) = (B(i) - ( A(i,i-1) * AuxBetaAlpha(i-1,1))) / (A(i,i) - A(i, i-1) * AuxBetaAlpha(i-1, 2));
                AuxBetaAlpha(i,2) = A(i,i+1) / (A(i,i) - A(i,i-1) * AuxBetaAlpha(i-1,2)); 
            end
            AuxBetaAlpha(s(1),1) = (B(s(1)) - A(s(1), s(1)-1) * AuxBetaAlpha(s(1)-1,1)) / (A(s(1), s(1)) - A(s(1), s(1)-1) * AuxBetaAlpha(s(1)-1, 2));
            AuxBetaAlpha(s(1),2) = 0;
            res = AuxBetaAlpha;
        end
    end
end
\end{lstlisting}
\subsection{Определение числа обусловленности матрицы}
\begin{lstlisting}
classdef cond_matrix 
    methods (Static)
        function res = condValue(A)
            B = inv(A);
            normA = cond_matrix.findNorm(A, 2);
            normB = cond_matrix.findNorm(B, 2);
            res = normA * normB;
        end

        function res = findNorm(A, power)
            pA = arrayfun(@(x) abs(x).^power, A);
            absMatrixSum = sum(sum(pA));
            res = nthroot(absMatrixSum, power);
            %res = svds(A, 1); like a matlab
        end
        
        function res = testStart()
            %res = cond_matrix.condValue([1 2 4; 5 1 2; 9 6 4]);
            %res = cond_matrix.condValue([2 -1 -1; 1 3 -2; 1 2 3]);
            res = cond_matrix.condValue([0.78 0.563; 0.913 0.659]);
        end
    end
end
\end{lstlisting}

\end{document}
