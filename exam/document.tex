\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage{upquote}
\usepackage{datetime}
\usepackage{multicol}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{enumitem}

\begin{document}
\section{Представление чисел в памяти. Погрешности.}
Мнж-во цел. чисел бесконечно, а проц. ограничен разрядной сеткой, кот-я
может оперировать только конечным подмножеством.
Обычно выделяется 4байта что позволяет представлять цел.числа в диапазоне $\pm 2
\cdot 10^9$.

В для решения задач в основном используют целые числа, в комп-е они
представляются как числа с плав. тчкй.
$\pm m \cdot 10^n$, где m-мантисса, 10-основание, n-порядок.
Нормализованная запись: $\pm 0.m \cdot 10^n$.
Число с фикс. точкой: -253.5
$x=\pm(\frac{d1}{\beta} + \frac{d2}{\beta^2} + \frac{dk}{\beta^k})\cdot \beta^n$
, где $\beta$ - основание системы, k - разрядность мантиссы, n - порядок, $d_i$
- числа от 0 до $\beta-1$, x - число.

Если я попробую записать число меньшее чем допустимо - запишется 0, если больше
чем допустимо, запишется самое большое допустимое число.

 \begin{table}[h!]
  \begin{tabular}{|l|l|l|l|}
  \hline
  \bfseries $\pm$ & мантисса & $\pm$ & порядок \\
  \hline
  \end{tabular}
\end{table}
Погрешность - мера точности для приближенных чисел. $x_0$ - точное знач., 
$\Delta x = |x_0 - x |$ - абсол. погр., $\delta x = \frac{\Delta x}{x_0}*100\%$
- относит. погр.\\
\begin{math}
\begin{array}{rl}
  \underline{a=a_0 \pm \Delta a} & 1) \Delta(a\pmb)= \Delta a + \Delta b\\
  \underline{b=b_0 \pm \Delta b} & 2) \delta(a \cdot or / b) = \delta a + \delta b \\
  3) \delta(a^n) = n*\delta a (мжн ум. погр if |a|<1) & 4) \Delta y = |f'(x_0)|\cdot \Delta x
\end{array}
\end{math}
Источники:модель,исх.данные, числ м-ды(интегр., ряды, табл.данн.),окргл. табл.
сетки.

\section{Обусловленность. Устойчивость и сходимость алгоритмов.}
Нек-е задачи очень чувствительны к неточностям в исх. данных - это устойчивость.
Пусть есть y(x), если исходн. величина $x$ - имеет погрешность $\Delta x$, то
результат $y$ имеет погрешность $\Delta y$: задача \textbf{устойчива} по
исх. пар-у $x$ если $y$ непрерывно от нее зависит, если малое приращение к
$\Delta x$ приводит к малому приращению $\Delta y$. О неустойчивых задачах
говорят, что они \textbf{чувствительны}, к входным данным.

Задача корректна, если для любых значений исходных данных, из некот-го класса,
ее решение существует, оно единственно и устойчиво.

Сходимость - близость получаемого решения задачи к истинному решению.\\
Сходимость итерационного процесса - способность итерационного алгоритма
достигать оптимума целевой функции, или подходить достаточно близко к нему, за
конечное число шагов. Скорость сходимости алгоритмов — один из важнейших
показателей качества аналитических моделей.

Под обусловленностью вычислительной задачи понимают чувствительность ее решения
к малым изменениям входных данных. Задачу называют хорошо обусловленной, если
при малых изменениях входных данных результат также изменяется незначительно.

\section{Прямые методы для ЛУ. Гаусс, Краут-Халецки, прогонка.}
Задача имеет 1 решение если: все у-я линейно независ., если кол-во уравнений =
кол-ву неизвестных. Прямые методы (подстановка, Крамер, Гаусс, Кр-Хл, прогонка.)

Гаусс - прямой ход (привидение матрицы к верхней \rhd) и обратный (вычисление
$x$ начиная с последней строки).\\
\begin{math}
\begin{array}{rl}
  a_1, b_1, c_1 = y_1 &\\
  a_2, b_2, c_2 = y_2 & I \cdot \frac{a_2}{a_1} + II =  \tilde{II}\\
  a_3, b_3, c_3 = y_3 & I \cdot \frac{a_3}{a_1} + III =  \tilde{III}
\end{array}
\end{math}
Гаусс с выбором ведущего элемента: если $|a_i| max $ в столбце - то перставляем
строку наверх (избавляет от деления на маленьк. числа).

Кр-Хл - представляем матр. $A$ как перемножение 2х матриц $A=C*D$, где С -
нижняя \rhd, а D - верхняя.
\begin{math}
\begin{array}{lr}
  c_{11}, _, _           & 1, d_{12}, d_{13}\\
  c_{21}, c_{22}, _      & _, 1, d_{23}  \\
  c_{31}, c_{32}, c_{33} & _, _, 1 \\
\end{array}
\end{math} 
Где $c_{i1} = a_{i1}$, $d_{1j} = a_{1j}/a{11}$ , 
$c_{ij} = a_{ij} - \sum\limits_{k=1}^{j-1} c_{ik} * d_{kj}$,
$d_{ij} = (a_{ij} - \sum\limits_{k=1}^{i-1} c_{ik} * d_{kj}) / c_{ii}$ \\
$AX = b -> CDX = B -> DX = Y and CY = B$ \\
$CY = B$ вычисляется как обратных ход Гаусса но сверху - узнали $Y$ \\
$DX = Y$ вычисляется как обратных ход Гаусса $X$. 

М-д прогонки - используется для 3х-диагональных матриц.
\begin{enumerate}
  \item $ x_1 
  = \underbrace{\frac{b_1}{a_{11}}}_\text{ $\beta 1$} 
  - \underbrace{\frac{a_{12} \cdot x_2}{a_{11}}}_\text{ $\alpha 1$} 
  = \beta 1 - \alpha 1 \cdot x_2$
  \item $a_{21}(\beta 1 - \alpha 1 \cdot x_2) + a_{22}x_2 + a_{23}x_3=b2$
  раскроем скобки $a_{21}\beta{1} - a_{21} \alpha{1} x_2 + a_{22}x_2 +
  a_{23}x_3=b2$, 
  $x_2(a_{22} - a{21}\alpha{1}) + a_{23}x_3 + a_{21}\beta{1} = b_2$,
  $x_2 = \underbrace{\frac{b_2 - a_{21}\beta{1}}{a_{22} - a_{21}\alpha{1}}}_\text{ $\beta 2$}
  - \underbrace{\frac{a_{23}}{a_{22} - a_{21}\alpha{1}}}_\text{ $\alpha 2$}\cdot x_3 
  = \beta{2} - \alpha{2} \cdot x_3$
  \item  $x_3 = \beta{3} -\alpha{3} \cdot x_4$\ldots
\end{enumerate}
$\beta{i} $- везде константа, $\alpha{i}$ - константа, говорит с каким коэф.
нужно брать $x_{i+1}$ чтобыполучить $x_{i}$.
$\beta{i} = \frac{b_i - a_{ii-1} \cdot \beta_{i-1}}{a_{ii} - a_{ii-1} \cdot \alpha_{k-1}}$
$\alpha{i} = \frac{a_{ii+1}}{a_{ii} - a_{ii-1} \cdot \alpha_{k-1}}$

\section{Обусловленность матрицы. Точность решения системы. Нормы вектора и матрицыю Способы оценки числа обусл. матрицы}
Величина  $Cond(A) = ||A|| \cdot ||A^-1||$ называется числом обусловленности
матрицы A. $Cond(A)$ определяет, насколько погрешность входных
данных может повлиять на решение системы; всегда $Cond(A) \geq 1$. Хотя число
обусловленности матрицы зависит от выбора нормы, если матрица хорошо обусловлена, то её число
обусловленности будет мало при любом выборе нормы.

Эвклидова норма вектора: $||x|| = \sqrt{x_1^2 = x_2^2 + x_3^2 + ..}$,
Манхеттенская норма вектора: $||x|| = |a_1| + |a_2| ..$,
Норма матрицы: максимальная норма одного из векторов матрицы.\\
1-теоретический $Cond(A) = = ||A|| \cdot ||A^-1||$\\
2-экспериментальный $\frac{X*}{X} \leq Cond(a) \cdot \frac{B*}{B}$, 
10< 1000 < 8

\section{Итерационные методы решения ЛУ}
М-д Якоби(метод простых итераций): $Ax = b$ -> $0 = b- Ax$ /*t -> 
$0=(b-Ax)t $ /+x -> x = $x=(b-Ax)t + x$ -> $x = tb - Axt + x$ ->
$x = (E - At)x + tb $ /B=E-At -> $x = Bx + tb$. Задаемся точностью.

М-д Гаусса Зейделя: выразим $x_1 x_2 x_3$ из \underline{соответствующих}
уравнений:\\
\begin{math}
\begin{array}{l}
  x_1^k = \frac{1}{a_{11}} (b1 - a_{12}x_2^{k-1} - a_{13}x_3^{k-1})\\
  x_2^k = \frac{1}{a_{22}} (b2 - a_{21}x_1^{k} - a_{23}x_3^{k-1})\\
  x_3^k = \frac{1}{a_{33}} (b3 - a_{31}x_1^{k} - a_{32}x_3^{k})
\end{array}
\end{math} 

\section{Инт.Апр. Лагранж, Ньютон}
АЦП. Интерполяция - восполнение данных, искусственная дискретизация. Через
точки. Экстраполяция - если вышла за интервал интерполяции. Интерп. $f$
представляем в виде суперпозиций: $f(x) = a_0f_0(x) + a_1f_1(x)..$, $f_i$ -
базис (Пример со степенным рядом). Теорема: для любого кол-ва табличных данных
есть только 1 интерполирующий полином, проходящий через все точки (порядок
n(точки)-1).

Лагранж: составляются коэффициенты по следующему правилу (n'ый элемент не
входит ни в числитель ни взнаменатель) для каждого x из табл.
 $l_n(x)= \frac{(x-x_0)(x-x_1)(x-x_2)\ldots (x-x_{n-1})}{(x_n-x_0)(x_n-x_1)
 \ldots (x_n-x_{n-1})}$, после составляется полином $L(x) = y_0l_0(x) +
 y_1l_1(x) + y_2l_2(x)\ldots$
 
Ньютон: 
\begin{table}[!h]
  \begin{tabular}{|l|l|l|l|l|l|}
  \hline
  \bfseries \#& x  & y0  & y1 & y2 & y3\\
  \hline
  \bfseries 1 & -1 & 1  &    &    &  \\  
  \hline
  \bfseries   &    &    & $\frac{11-1}{17+1} = \frac{5}{9}$ &  & \\  
  \hline
  \bfseries 2 & 17 & 11 & & $\frac{\frac{3}{11} - \frac{5}{9}}{6+1} =
   \frac{27 - 55}{99 * 7} =
   \frac{-4}{99}$ & \\
  \hline
  \bfseries   &    &    & $\frac{8-11}{6-17} = \frac{3}{11}$ & 
  & $\frac{\frac{61}{154} + \frac{4}{99}}{10+1} =
  \frac{549 + 56}{1386 * 11} = 
  \frac{5}{126}$\\
  \hline
  \bfseries 3 & 6  & 8  & & $\frac{\frac{-5}{2} - \frac{3}{11}}{10-17} =
  \frac{-55 - 6}{22 * (-7)} =
  \frac{61}{154}$ & \\
  \hline
  \bfseries   &    &    & $\frac{-2-8}{10-6} = \frac{-5}{2}$ & & \\
  \hline
  \bfseries 4 & 10 & -2 & & & \\
  \hline
  \end{tabular}
\end{table} \\
$N(x) = y0_1 +y1_1 ·(x -x_1)+y2_1·(x-x_1)·(x- x_2)+y3_1·(x- x_1)·(x- x_2)·(x- _x3)$
Остаточный член интерпол. ф-лы.

\section{Сплайн интерполяция}
Отрезки между узлами характеризуются сплайнами. Каждому сплайну принадлежит 4
коэф. ${a, b, c, d}$. Если x - из промежутка, описываемого i-ым сплайном, то
для вычисления y необходимо: (нумерация точек и сплайнов с 0 - $x_i$ - сначала
интервала сплайна ) $h = x - x_i, y = a_i + b_ih + c_ih^2 + d_ih^3$.

Поиск коэфф.: spl_i.a = p[i].y,  spl_i.h = p[i+1].x - p[i].x\\
Составляем матрицу для c (eq - одно у-е, вмего n-2)\\ 
eq[i-2] = spl_{i-1}.h \\
eq[i-1]   = 2 * (spl_{i-1}.h + spl_{i}.h) \\
eq[i] = spl_{i}.h \\
b_i = 3 * ((p[i+1].y - p[i].y)/spl_{i}.h - (p[i].y-p[i-1].y)/spl_{i-1}.h)
Вычислим d и b\\
spl_i.d = (spl_{i+1}.c - spl_{i}.c) / (3 * spl_{i}.h)\\
spl_{i}.b = ((p[i+1].y - spl_{i}.a - spl_{i}.c * spl_{i}.h^2 - spl_{i}.d * spl_{i}.h^3 )/ spl_{i}.h)

\section{Аппроксимация МНК}
$\Delta i = fk(x_i) i y_i$, МКО -> $\sum\limits_{i=0}^n \Delta i^2 -> min$
используется в качестве критерия в МНК. $f_k = = a_0f_0(x) +a_1f_1(x)..a_nf_n(x)$
 составляем систему\\ 
\begin{math}
\left\{
\begin{array}{lr}
  \frac{\delta s }{\delta a_0} = 2 (\sum\limits_{0}^nf_k(x_i) -y_i) \cdot
  f_0(x_i) & -> \sum\limits_{0}^n y_i \cdot f_0(x_i)\\\\
  \frac{\delta s }{\delta a_1} = 2 (\sum\limits_{0}^nf_k(x_i) -y_i) \cdot
  f_1(x_i) & -> \sum\limits_{0}^n y_i \cdot f_1(x_i)\\
  \frac{\delta s }{\delta a_n} = 2(\sum\limits_{0}^nf_k(x_i) -y_i) \cdot
  f_n(x_i) & -> \sum\limits_{0}^n y_i \cdot f_2(x_i)\\
\end{array}
\end{math}
Пример k=2 - выбранный порядок. тогда f(x) = a_0 + a_1x + a_2x^2
xy_0 = {-1, 1}, xy_1 = {17, 11}, xy_2 = {6, 8}, xy_3 = {10, -2}.\\
\begin{math}
\left\{
\begin{array}{ll}
  4a_0 + 32a_1 + 426a_2 = 18 & 4$-колво точек$, 32=\sum x_i, 426=\sum x_i^2, 18=\sum y_i\\
  32a_0 + 426a_1 + 6128a_2 = 214  & 6128 =\sum x_i^3, 214 =\sum y_ix_i\\
  426a_0 + 6128a_1 + 94818a_2 = 3268 & 3268 = \sum y_ix_i^2
\end{array}
\end{math}
Решаем систему, подставляем а в f.

\section{Взаимно-орт. ф. Аппр Фурье, Чебышев, Лежандр Лаггер}
Ряд функций ортогонален, если $\int\limits_{a}^bf_i(x) \cdot f_j(x) dx =
(i==j)? \delta : 0$ (Если точек более 100 то можно $\int dx = \sum $)\\
\begin{math}
\left\{
\begin{array}{lll}
  a_0 \cdot \sum f_0^2(x_i) &+ a_1 \cdot \sum f_1^2(x_i) f_0^2(x_i) &+ \cdots
  = \sum \limits_{i=0}^n y_i*f_0(x_i)\\
  \vdots  &\ddots &\vdots \\
  &  &+ a_k \cdot \sum f_k^2(x_i) = \sum \limits_{i=0}^n y_i*f_k(x_i)
\end{array}
\end{math}
Все кроме диагонали = 0. Далее нужно просто выразить значения с каждой строки
Фурье: функции обладают взаимной орт. на интервале [-\pi; \pi].

Чебышев: $T_0(x)=1; T_1(x)=x; T_{k+1}(x)=2x* T_k(x) - T_{k-1}(x);$\\
Бессель: $U_0(x)=1; U_1(x)=2x; U_{k+1}(x)=2x * U_k(x) - U_{k-1}(x); $\\
Лежандр: $P_0(x)=1; P_1(x)=x; P_{k+1}(x)=((2k+1)*x*P_k(x) -kP_{k-1}(x))/(k+1)$\\
Лаггер: $L_0(x)=1; L_1(x)=1-x; L_{k+1}(x)=((2k+1-x)L_k(x) -kL_{k-1}(x))/(k+1);$\\

\section{Безье. Бернштайн}
\begin{math}
\left\{
\begin{array}{ll}
  \beta_n(t)_x = \sum\limits_{i=0}^nx_i \cdot \Phi_{i,n}(t)& \Phi_{i,n}(t) =
  C_n^i \cdot t^i \cdot (1-t)^{n-i}\\
  \beta_n(t)_y = \sum\limits_{i=0}^ny_i \cdot \Phi_{i,n}(t)& C_n^i =
  \frac{n!}{i!(n-i)!}, 0 < t < 1\\
\end{array}
\end{math}

De-Casteljou: 1) соединяем точкм по порядку; 2) на каждом отрезке считаем новую
точку: xc = xa + 0.3(x_b -x_a), yc = ya + 0.3(y_b -y_a); 3) Делим все отрезки в
выбранной пропорции и соединяем точки(они называются точки Безье).

\section{Дифференцирование. Конечные разности} 
В точках max и min =0. $y'(x) = \lim_{\Delta x to 0} \frac{\Delta y}{\Delta x}
=\frac{\Delta y}{\Delta x} =tg(x) $ к графику. Задача - получить таблицу x/y
где шаг - константа.\\
\begin{math}
\left\{
\begin{array}{ll}
  y'_k = \frac{y_k - y_{k-1}}{h} & $левая разн. -нельзя использовать для 1ой
  точки$\\
  y'_k = \frac{y_{k+1} - y_{k}}{h}& $прав. разн.(и лев.)хорошо работают где нет
  экстремумов$\\
  y'_k = \frac{y_{k+1} - y_{k-1}}{2h}& $центр. разн. более точен чем л и п$
  \\
\end{array}
\end{math}
Погрешность аппроксимации производной $R^{(k)}(x) = f^{(k)}(x) = \phi^{(k)}(x)$

%Порядок точности - это степень многочлена с помощью кот-го можно продиффер. без
%ошибок.
%$y'_k= \frac{y_k - y_{k-1}}{h}$

\section{М-д Ньютона Котеса для интег.}
Виды интеграла(определенный, неопределенный, с переменным пределом). 1)
необходимо превратить данные из аналитич ф-ции в табличные с определенным шагом.
(для определенного $\int\limits_{a}^b y(x)dx = \sum\limits_{i}^n S_i$, для
неопределенного площадь будет накапливаться $F(x_i)=F(x_{i-1}+s_i), F(a)=0$).

Методы  численного  интегрирования (квадратурные  формулы)  используют
геометрическую  трактовку  интеграла  как  площади,  ограниченной  графиком
функции, OX и  пределами  интегрирования. Все методы отличаются  способом
вычисления  площади  элементарного  фрагмента  S.

М-д прмоугольников: $S_i= y_{i-1}*h$, м-д трапеций: $S_i= \frac{h}{2}(y_{i-1}
+ y_i)$, м-д Симпсона (порабол - интерполирует по 3м точкам): $ \frac{h}{6}(y_{i-1}
+ 4y_i+y_{i+1})$ Если нужна больше точность, берем больше точек, и полином
соотв. порядка.

\section{Квадратура Гаусса}
$\int\limits_{a}^b y(x)dx = (\sum\limits_{i=1}^k A_{i} \cdot y(x_i))*С$, где
к-порядок. Нужно найти все А и все t (2k переменных). 
$t_i$  корни многочлена Лежандра соответствующего порядка. Для аналитической
ф-ции, $A_i=\frac{2}{(1-t_i^2)(P'k(t_i)^2)}$. Используя м-д Гаусса, мы решаем
интеграл на интервал [-1, 1], поэтому после нахождения результата для $\int\limits_{-1}^1y(t)dt = A_1y(t_1) + \ldots$
нужно произвести перевод результата в исходные пределы. 

\section{Решение нелин.у-й. бисекция, (сек)хорды, золот.сеч. параболы}
$f(x)$ дб гладкая, дифференцируемая фция. Решением является такой x* при котором
фция пересекает ОХ.
У-я бывают Алгебраические($a_0 + a_1x + .. = 0 $ порядок не выше 4),
Трансцендентные: все остальные (тригонометрические, логарифмические).Проблема:
все численные методы предназначены для поиска одного корня, хотя их мб много;
для запуска любого численного метода в качестве входного параметра необходимо
задать интервал, где существует хотя бы один корень.
Все м-ды итерационные. Сравнивать можно только по сходимости ($|x_{k+1}- x_k|
< |x_k - x_{k-1}|$) и скорости.
1шаг) выбор интервала.\\
\begin{multicols}{2}
2шаг бис) $x=\frac{a+b}{2}$ \\
3шаг бис) ($f(a)\cdot f(x) \leq 0 $)? b=x : a=x\\
4шаг бис) if $|b-a| < E $ stop : step 2.\\
p=1 \\
- самый медленный из методов\\
+ абсолютная сходимость с любой E\\
+ предсказуем (можно посчитать кол-во итераций)\\
\end{multicols}

\begin{multicols}{2}
$\frac{m}{n}= \frac{n}{m+n} -> m=n^2$\\
$n^2 + n - 1 = 0 -> n = 0.618, m = 0.382$\\
2шаг зс) ($|f(a)| > |f(b)| )? x=a+0.618(|b-a|) : x=a+0.382(|b-a|)$\\
p=1 \\
- быстрее м-да бисекции в 1.5 раза\\
+ абсолютная сходимость с любой E\\
+ предсказуем (можно посчитать кол-во итераций)\\
\end{multicols}

\begin{multicols}{2}
Проводим прямую от а к б, и пересечение с OX принимаем за x
2шаг х) $x=b-\frac{b-a}{f(b)-f(a)} * f(b)$\\
3шаг х) см бисекц.\\
4шаг х) if(|x_{i-1} - x_i| < E)? stop : step 2\\
p=1 \\
\end{multicols}

\begin{multicols}{2}
м-д порабол - точечный\\
2шаг п) см бисекцию\\
3шаг п) берем f(a), f(x_0), f(b) - интерполируем по Лагранжу.\\
$L_2 = a_0+a_1x+ a_2x^2 = 0 -> x_{1,2}$ - выбираем тот, что из интерваба аб.\\
4шаг п) $if(x_1 \in [x_0, b])? a = x_0, x_0 = x_1 : b = x_0, x_0 = x_1$\\
5шаг п) $if |x_1-x_0| < E ? stop : step 3$ \\
+ квадратная сходимость \\
+ 4 шаг обеспечивает сходимость \\
- шаг 3 очень затратный
\end{multicols}

\section{Реш.нел. ур. Ньютон}
Метод касательных. Проводим касательную к f(x) в точке x. Пересечение
касательной и прямой принимаем за х.
 1) выбрали интервал; 2)$x_0 = \frac{a+b}{2}$; 3) $x_{k+1} = x_k -
 \frac{f(x)}{f'(x)}$; 4) if $|x_{k+1} - x_k| < e? stop : step 3$.
 Иногда применяют Ньютона с коррекцикей:
 3) $x_{k+1} = x_k - \alpha \ frac{f(x)}{f'(x)}, if(|f(x_{k+1})| \geq
 |f(x_{k})| ? \alpha = \alpha /2 $;
 
\section{М-ды решения систем нелин. у-й. М-д Ньютона,Простых итераций}
Ньютон
\begin{math}
\left\{
\begin{array}{l}
  f_1(x_1 \ldots x_n) = 0 \\
  \vdots \\
  f_n(x_1 \ldots x_n) = 0
\end{array}
\end{math}\\
$X_{k+1} = X_k - W^{-1} (X_k) * F(X_k)$ где W(x) - матрица якоби\\

W(X) = 
\begin{bmatrix} 
  $\delta f_1 / \delta k_1$ & \cdots & $\delta f_1 / \delta k_n$ \\
  \vdots & \ddots & \vdots \\ 
  $\delta f_n / \delta k_1$ & \cdots & $\delta f_n / \delta k_n$ 
\end{bmatrix}\\

Пр.Ит.
\begin{math}
\begin{array}{l}
  x_1 + \\
  \ldots \\
  x_n + \\
\end{array}
\left\{
\begin{array}{l}
  f_1(x_1 \ldots x_n) = 0 + x_1\\
  \vdots \\
  f_n(x_1 \ldots x_n) = 0 + x_n
\end{array}
\end{math}\\

$X_{k+1} = \Phi(X_k)$

\section{Задачи оптимизации. М-ды спуска}
Задачей оптимизации в называется задача о нахождении экстремума (минимума или
максимума) функции в некоторой области.
1. Метод Монте-Карло (случайного поиска)\\
2. Методы Спуска: \textbf{покоординатный поиск}: $x_0$ - начальное приближение,
двигаемся по одной координате в сторону убывания, пока функция не начнет расти (сразу
фиксируем координату). После того как прошли по всем координатам, в качестве
начального приближения можно взять найденное решение. Отметим, что данный метод
сводит задачу поиска наименьшего значения функции нескольких переменных к
многократному решению одномерных задач оптимизации. \textbf{Градиентный поиск}:
$G= (\frac{\delta F}{\delta x_1}, \frac{\delta F}{\delta x_2})$ Идея в том,
чтобы идти в направлении наискорейшего спуска, которое задается антиградиентом.
\textbf{метод наискорейшего спуска (сочетание первых двух)}:  - вначале считается градиент,
он задаёт направление, после используем покоординатный . Спусаемся, пока       
уменьшаемся, потом пересчитывается градиент, и повторяем.

\section{Оптимизация генетическими алгоритмами}
является эволюционным методом. 
\begin{enumerate}
  \item выбор начальной популяции n = 1000 особей (случ. обр. выбираем 1000
  разных решений);
  \item Кроссовер - скрещиваем осбои попарно - получаем 2000 решений;
  \item Отбор - выбираем 1000 лучших решений (разбиваются на пары, и
  сравниваются друг с другом);
  \item Мутация - внесение резкого случ. изменения в одну особь.
  \item Если > 85\% популяции одинакого - стоп, иначе шаг 2.
   
  
\end{enumerate} 
\end{document}